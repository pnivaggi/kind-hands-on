# Getting Started

This lab is based on `kind` Kubernetes installer. `kind` or **k**ubernetes **in** **d**ocker is a suite of tooling for local Kubernetes ‚Äúclusters‚Äù where each ‚Äúnode‚Äù is a Docker container. `kind` is targeted at testing Kubernetes and is also very convenient for trainings.
`kind` is divided into go packages implementing most of the functionality, a command line for users, and a ‚Äúnode‚Äù base image. Please refer to <https://kind.sigs.k8s.io/> for more information.

## Task 1. Define Kubernetes Cluster config file

Create a cluster configuration file defining a cluster with one control plane node and two worker nodes.

```bash
tee kind-config.yaml <<EOF                           
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
- role: worker
- role: worker
EOF
```

## Task 2. Deploy Kubernetes cluster

Install a Kubernetes cluster named `demo` with `kind` CLI refering to the `kind-config.yaml` configuration file. `kind` CLI is already installed in the lab environement.

```bash
kind create cluster --name demo --config kind-config.yaml
```

You should have an output similar to:

```console
Creating cluster "demo" ...
 ‚úì Ensuring node image (kindest/node:v1.25.0) üñº 
 ‚úì Preparing nodes üì¶ üì¶ üì¶  
 ‚úì Writing configuration üìú 
 ‚úì Starting control-plane üïπÔ∏è 
 ‚úì Installing CNI üîå 
 ‚úì Installing StorageClass üíæ 
 ‚úì Joining worker nodes üöú 
Set kubectl context to "kind-demo"
You can now use your cluster with:

kubectl cluster-info --context kind-demo

Have a nice day! üëã
```

## Task 3. Check the cluster with Kind CLI

```bash
kind get clusters
```

```bash
kind get nodes --name demo
```

You should have a similar output.

```
demo-control-plane
demo-worker
demo-worker2
```

## Task 4. Check Kubectl config and current context

```bash
kubectl config current-context
```

```bash
kubectl config view
```

You should have a similar output.

```yaml
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://127.0.0.1:61353
  name: kind-demo
contexts:
- context:
    cluster: kind-demo
    user: kind-demo
  name: kind-demo
current-context: kind-demo
kind: Config
preferences: {}
users:
- name: kind-demo
  user:
    client-certificate-data: REDACTED
    client-key-data: REDACTED
```

## Task 6. Check the cluster with Kubectl

`kubectl` command line interface is already installed in your lab environment. You can use `kubectl` to check the cluster has been deployed properly

```bash
kubectl cluster-info --context kind-demo
```

You should have a similar output.

```
Kubernetes control plane is running at https://127.0.0.1:42563
CoreDNS is running at https://127.0.0.1:42563/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

```bash
kubectl get nodes 
```

You should have the similar output. Notice the ready state for the 3 nodes, 1 control plane and 2 workers.

```console
NAME                 STATUS   ROLES           AGE   VERSION
demo-control-plane   Ready    control-plane   11m   v1.25.0
demo-worker          Ready    <none>          11m   v1.25.0
demo-worker2         Ready    <none>          11m   v1.25.0
```

## Task 5. Check the cluster with Docker

You can use `docker` command line interface to list the containers running on the lab environment.

```bash
docker ps
```

You should have a similar output. Notice the image release used for the nodes running as containers: `kindest/node:v1.25.0`

```console
CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                       NAMES
6fbf0bfd2ddb   kindest/node:v1.25.0   "/usr/local/bin/entr‚Ä¶"   16 minutes ago   Up 16 minutes                               demo-worker
1e2094700a37   kindest/node:v1.25.0   "/usr/local/bin/entr‚Ä¶"   16 minutes ago   Up 16 minutes                               demo-worker2
a7275fc08a88   kindest/node:v1.25.0   "/usr/local/bin/entr‚Ä¶"   16 minutes ago   Up 16 minutes   127.0.0.1:61353->6443/tcp   demo-control-plane
```

## Task 7. Check the Pods already deployed

Pods are the smallest deployable units of computing that you can create and manage in Kubernetes. A Pod (as in a pod of whales or pea pod) is a group of one or more containers, with shared storage and network resources, and a specification for how to run the containers.

Enter the below `kubectl` command to list all the Pods deployed on the cluster

```bash
kubectl get pods -A
```

You should have a similar output.

```console
NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE
kube-system          coredns-565d847f94-4xqw9                     1/1     Running   0          20m
kube-system          coredns-565d847f94-vb85m                     1/1     Running   0          20m
kube-system          etcd-demo-control-plane                      1/1     Running   0          20m
kube-system          kindnet-bq65m                                1/1     Running   0          20m
kube-system          kindnet-pzjzs                                1/1     Running   0          20m
kube-system          kindnet-qmlvp                                1/1     Running   0          20m
kube-system          kube-apiserver-demo-control-plane            1/1     Running   0          20m
kube-system          kube-controller-manager-demo-control-plane   1/1     Running   0          20m
kube-system          kube-proxy-8xdv8                             1/1     Running   0          20m
kube-system          kube-proxy-d2vgq                             1/1     Running   0          20m
kube-system          kube-proxy-qmzv8                             1/1     Running   0          20m
kube-system          kube-scheduler-demo-control-plane            1/1     Running   0          20m
local-path-storage   local-path-provisioner-684f458cdd-b5j6x      1/1     Running   0          20m
```

You can notice that the Kubernetes components mentioned in the architecture section are deployed as Pods in a specific namespace named `kube-system`. In Kubernetes, namespaces provides a mechanism for isolating groups of resources within a single cluster.

The components include etcd , kube-apiserver, kube-controller-manager, kube-scheduler. In addition, few others applications are deployed like:

- coredns: it is a DNS server responsible for name resolution and integrates with Kubernetes for service discovery. With coredns, Pods in the same namespace can refer to each other only by their Pod names.
- kindnet: it is the default CNI (Container Network Interface) responsible for managing Pod network interface and overlay network between the nodes in the cluster. Kind supports other CNI like Calico.
- local-path-provisioner: it provides a way for the Kubernetes users to utilize the local storage in each node. Based on the user configuration, the Local Path Provisioner will create hostPath based persistent volume on the node automatically.
- kube-proxy: it is related to the Kubernetes services configuration to expose application to the external world or other application within the cluster. It is deployed on each and every node. It can do simple TCP, UDP, and SCTP stream forwarding or round robin TCP, UDP, and SCTP forwarding across a set of backends.

From the table, the `READY` column gives an indication of how many containers are running in the Pod and how many are ready. The primary purpose of a multi-container Pod is to support co-located, co-managed helper processes for a main program like logs, metrics collection (sidecar containers) or facilitate access to external resource (reverse-proxy, adapters containers). 

The `STATUS` column indicates the Pods lifecycle status. Pods follow a defined lifecycle, starting in the `Pending` phase, moving through `Running` if at least one of its primary containers starts OK, and then through either the `Succeeded` or `Failed` phases depending on whether any container in the Pod terminated in failure.
